{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Enunciado_tarea_2_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "deepnote_notebook_id": "c37ad86b-e42d-4691-aaac-92b1fd4fc164",
    "deepnote_execution_queue": [],
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_LwBzSZFjl2",
        "cell_id": "00000-46e90bdf-fa42-48d3-9adf-06ba9239d11d",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "<hr style=\"height:2px;border:none\"/>\n",
        "<h1 align='center'> <img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
        "\n",
        "INF-395 / 477 / 577 Tarea 2 Redes Neuronales Artificiales - 2020-2 </h1>\n",
        "\n",
        "<H3 align='center'> Integrantes: Kevin Reyes - Diego Quezada </H3>\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "\n",
        "**Temas**  \n",
        "* Manipulaciones en tensorflow, keras, pandas y numpy\n",
        "* Recurrent Neural Networks\n",
        "* LSTM, GRU\n",
        "* Autoencoders\n",
        "* GAN\n",
        "\n",
        "**Formalidades**  \n",
        "* Equipos de trabajo de 2 personas (*Ambos estudiantes deben estar preparados para presentar la tarea el día de la entrega*)\n",
        "* El entregable debe ser un _Jupyter Notebook_ incluyendo los códigos utilizados, los resultados, los gráficos realizados y comentarios. Debe seguir una estructura similar a un informe (se debe introducir los problemas a trabajar, presentar los resultados y discutirlos). Si lo prefiere puede entregar un _Jupyter Notebook_ por pregunta o uno para toda la tarea, con tal de que todos los entregables estén bien identificados y se encuentren en el mismo repositorio de _Github_.\n",
        "* Se debe preparar una presentación del trabajo realizado y sus hallazgos. El presentador será elegido aleatoriamente y deberá apoyarse en el _Jupyter Notebook_ que entregarán. \n",
        "* Formato de entrega: envı́o de link del repositorio en _Github_ ( en caso de ser repositorio privado, invitar como colaborador al usuario de github \"Aerlio\") al correo electrónico del ayudante (*<tomas.ochoa.14@sansano.usm.cl>*), en copia al profesor (*<cvalle@inf.utfsm.cl>*). Especificar el siguiente asunto: [INF395/477/577-2020 Tarea 2]\n",
        "* Fecha de entrega y presentaciones: 8 de Enero. Hora límite de entrega: 23:00. Cualquier _commit_ luego de la hora límite no será evaluado. Se realizará descuento por atrasos en envío del mail. \n",
        "\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "La tarea se divide en tres partes:\n",
        "\n",
        "[1.](#primero) RNNs para series de tiempo  <br>\n",
        "[2.](#segundo) RNNs para texto <br>\n",
        "[3.](#tercero) Autoencoders para imágenes <br>\n",
        "[3.](#cuarto) GANs para imágenes <br>\n",
        "\n",
        "La tarea tiene ejemplos de códigos con los cuales pueden guiarse en gran parte, sin embargo solo son guías y pueden ser creativos al momento de resolver la tarea. Soluciones creativas o elegantes serán valoradas. También en algunas ocaciones se hacen elecciones arbitrarias, ustedes pueden realizar otras elecciones con tal de que haya una pequeña justificación de por qué su elección es mejor o equivalente.\n",
        "Recuerden intercalar su código con comentarios y con celdas _Markdown_ con los comentarios de la pregunta y con cualquier analisis, fórmula o explicación que les parezca relevante para justificar sus procedimientos. \n",
        "Noten que en general cuando se les pide elegir algo o proponer algo no se evaluará mucho la elección en si, en cambio la argumentación detrás de la elección será lo más ponderado.\n",
        "\n",
        "**Es ÁLTAMENTE recomendado realizar esta tarea en _Colab_ de Google (https://colab.research.google.com/notebooks/intro.ipynb#recent=true), con el fin de no depender del rendimiento de su computador personal al momento de entrenar redes neuronales y poder compartir de forma fácil sus avances con su compañer@ de trabajo.** Si bien conlleva sus pros y contras utilizar _Colab_ , existirá una curva de aprendizaje personal que lo ayudará a sacar el mayor provecho a esta herramienta, por ejemplo aprendiendo a guardar los avances realizados, evitando tener que ejecutar todo el código cada vez que se abra _Colab_ . *Tip: Una vez abierto un notebook en _Colab_ ir a **entorno de ejecución**->**Cambiar tipo de entorno de ejecución**, y seleccionár TPU como acelerador por hardware para redes recurrentes y GPU para redes convolucionales.*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00007-62d835db-c7d0-46fc-b8e4-e8e1291fb644",
        "output_cleared": false,
        "source_hash": "89047012",
        "execution_millis": 11,
        "execution_start": 1609301107929,
        "deepnote_cell_type": "code",
        "id": "DzbZtmKPz0AP"
      },
      "source": [
        "import random"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irFPwfVg4QI9"
      },
      "source": [
        "os.environ['PYTHONHASHSEED'] = '0'\r\n",
        "np.random.seed(1)\r\n",
        "random.seed(1)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfAl-3Wu4TZR"
      },
      "source": [
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\r\n",
        "tf.compat.v1.set_random_seed(1)\r\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\r\n",
        "tf.compat.v1.keras.backend.set_session(sess)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVQdG3blVcZs",
        "cell_id": "00045-49b25fef-fe86-4801-bb4e-f95e250b7378",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "# 2. RNN sobre texto\n",
        "\n",
        "Hoy en dı́a, una aplicación relevante de las redes neuronales recurrentes es el modelamiento de texto y lenguaje natural. En esta sección abordaremos el problema de procesar sentencias de texto, proporcionadas por GMB (*Groningen Meaning Bank*), para reconocimiento de entidades y tagger. En específico, trabajaremos con el dataset proprocionado a través de __[Kaggle](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus)__, que está compuesto por más de un millón de palabras, a fin de realizar predicciones sobre distintas tareas del tipo *many to many* y *many to one*.\n",
        "\n",
        "<img src=\"https://i.stack.imgur.com/b4sus.jpg\" width=\"70%\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr4CUn7PYESQ",
        "cell_id": "00046-21afea16-338e-493f-b9eb-f93172069154",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "## 2.a Carga de datos y preprocesamientos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK7pjS1BZquJ",
        "cell_id": "00047-17811180-a509-4d63-9a5c-9f19eaa382c1",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "##### I) Investigue en la documentación del dataset cual es la tarea original para el cual fue propuesto, en particular cuál es la variable que buscamos predecir, a qué se refiere esta misma y por qué es necesario utilizar técnicas avanzadas para resolver esta tarea (¿no bastaría con un diccionario?).\n",
        "\n",
        "**Respuesta:**\n",
        "La tarea original del dataset fue identificar entidades nombradas (o etiquetadas) a partir de textos, en particular entidades como nombre y ubicación.\n",
        "La variable que buscamos predecir son la o las entidades que participan en una oración. esta se refiere a identificar información crucial o bien de interés\n",
        "de un texto. No bastaría con un diccionario pues este nos daría información acotada que no consideraría una arquitectura recurrente. Esta última nos permite identificar entidades de interés en\n",
        "oraciones complejas en donde la entidad no está explícita, por lo que no es posible obtener obtener una predicción correcta a partir de un simple diccionario.\n",
        "\n",
        "\n",
        "Cargue el conjunto de datos. Este conjunto de datos es bastante grande, por lo que como ven en el código propuesto, nos contentaremos con no considerar las lineas corruptas del registro.\n",
        "\n",
        "En esta primera instancia trabajaremos con la tarea de realizar un NER *tag* (**Named Entity Recognition**) sobre cada una de las palabras en las sentencias que se nos presenta en los datos. Esta tarea es del tipo *many to many*, es decir, la entrada es una secuencia y la salida es una secuencia, sin *shift*, por lo que necesitaremos una estructura de red adecuada a ésto. En primer lugar extraiga las columnas que utilizaremos del dataset **¿Por qué es conveniente utilizar *lemma* en vez de la palabra misma *word*?**  \n",
        "**Respuesta:** \n",
        "Porque cada palabra puede tener múltiples variaciones, por ejemplo, *trabajar* en inglés en los distintos\n",
        "tiempos y personas podría ser: work, worked, working y works, cada una de estas palabras tiene\n",
        "el mismo significado pero en distinto tiempo o persona, por lo que, es útil utilizar\n",
        "lemmatization para llevar todas las palabras a su raiz y así sacar el máximo de provecho\n",
        "al aprendizaje, ya que, en vez de tener que aprender work, worked, working y works, estaremos\n",
        "aprendiendo work y su uso se puede interpretar dado el contexto, esto es útil para nuestro\n",
        "problema en específico, ya que, para reconocer entidades en una secuencia no es relevante\n",
        "el tiempo o la persona que se use.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00066-3bd265f3-cd19-4a9a-99c1-9a323fe175be",
        "output_cleared": false,
        "source_hash": "8980a40e",
        "execution_millis": 9,
        "execution_start": 1609303105732,
        "deepnote_cell_type": "code",
        "id": "nLfHpEoZz0AS"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcORhXvIa5bh",
        "cell_id": "00048-e314c5b6-f909-4d31-b991-d03dcc63facd",
        "output_cleared": false,
        "source_hash": "c3ab4ff9",
        "execution_millis": 6423,
        "execution_start": 1609303000206,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c4c52ac-1398-4412-d82e-157a35c83acd"
      },
      "source": [
        "username=\"diegoquezada21\"\n",
        "key=\"afb1882970f4ac5726f12dda7bf92f7c\"\n",
        "!pip install -q kaggle\n",
        "api_token = {\"username\":username,\"key\":key}\n",
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = str(username)\n",
        "os.environ['KAGGLE_KEY'] = str(key)\n",
        "!kaggle datasets download -d abhinavwalia95/entity-annotated-corpus\n",
        "if not os.path.exists(\"/content/NER\"):\n",
        "    os.makedirs(\"/content/NER\")\n",
        "os.chdir('/content/NER')\n",
        "for file in os.listdir():\n",
        "    if file[-4:]==\".zip\":\n",
        "      zip_ref = zipfile.ZipFile(file, 'r')\n",
        "      zip_ref.extractall()\n",
        "      zip_ref.close()\n",
        "!ls"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "entity-annotated-corpus.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "entity-annotated-corpus.zip  ner.csv  ner_dataset.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YuvuL7vYgur",
        "cell_id": "00049-c9e65c78-529d-487c-9517-d84ee3cb5e35",
        "output_cleared": false,
        "source_hash": "b5a3d7ab",
        "execution_millis": 8636,
        "execution_start": 1609303010038,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "f2d6e84c-850f-4aad-e3f7-3e4753d24aaa"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df_ner = pd.read_csv(\"ner.csv\", encoding =\"cp1252\", error_bad_lines=False)\n",
        "df_ner.dropna(inplace=True)\n",
        "dataset = df_ner.loc[:,['lemma','tag','word','sentence_idx']]\n",
        "dataset[0:200]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 281837: expected 25 fields, saw 34\\n'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemma</th>\n",
              "      <th>tag</th>\n",
              "      <th>word</th>\n",
              "      <th>sentence_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>thousand</td>\n",
              "      <td>O</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>of</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>demonstr</td>\n",
              "      <td>O</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "      <td>have</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>march</td>\n",
              "      <td>O</td>\n",
              "      <td>marched</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>.</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>iranian</td>\n",
              "      <td>B-gpe</td>\n",
              "      <td>Iranian</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>offici</td>\n",
              "      <td>O</td>\n",
              "      <td>officials</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>say</td>\n",
              "      <td>O</td>\n",
              "      <td>say</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>they</td>\n",
              "      <td>O</td>\n",
              "      <td>they</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        lemma    tag           word  sentence_idx\n",
              "0    thousand      O      Thousands           1.0\n",
              "1          of      O             of           1.0\n",
              "2    demonstr      O  demonstrators           1.0\n",
              "3        have      O           have           1.0\n",
              "4       march      O        marched           1.0\n",
              "..        ...    ...            ...           ...\n",
              "195         .      O              .           9.0\n",
              "196   iranian  B-gpe        Iranian          10.0\n",
              "197    offici      O      officials          10.0\n",
              "198       say      O            say          10.0\n",
              "199      they      O           they          10.0\n",
              "\n",
              "[200 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcfFNDaqYiWn",
        "cell_id": "00050-3178ba3e-64b0-4d34-8bcd-81ec7dcf2deb",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "##### II) Para poder utilizar este conjunto de datos, debemos transformar nuestra tabla de palabras y sentencias, a una tabla donde cada entrada sea una sentencia, ademas codificando los distintos lemmas y tags como valores numéricos. Esto pueden realizarlo con alguna de las utilidades de keras o sklearn, sin embargo en el código siguiente se propone un metodo solo usando python y pandas. Pueden utilizar el método que deseen. Note eso si que independiente la aproximación que utilice debe comenzar desde 1 para la codificación, pues el valor 0 lo reservaremos para representar la ausencia de palabras más adelante.\n",
        "\n",
        "**Explique qué realiza cada linea del código.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bILC6YsLYjJM",
        "cell_id": "00051-0c770755-1ab1-49c2-9849-7ec3af8c5884",
        "output_cleared": false,
        "source_hash": "3e6890a1",
        "execution_millis": 12257,
        "execution_start": 1609303023265,
        "deepnote_cell_type": "code"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Crea un diccionario donde a cada lemma se le asigna un código numérico partiendo desde el 1\n",
        "lemma_to_code = {lemma:code+1 for code, lemma in enumerate(dataset.lemma.unique())}\n",
        "# Crea un diccionario donde a cada tag se le asigna un código numérico partiendo desde el 1\n",
        "tag_to_code = {tag:code+1 for code, tag in enumerate(dataset.tag.unique())}\n",
        "# Calcula la cantidad de lemmas\n",
        "n_lemmas = len(lemma_to_code) \n",
        "lemmas = dataset.lemma.unique()\n",
        "tags = dataset.tag.unique()\n",
        "# cambia el valor de cada registro de lemma en el dataset por el código numérico generado\n",
        "dataset['lemma'] = dataset.lemma.apply(lambda x: lemma_to_code[x])\n",
        "# cambia el valor de cada registro de tag en el dataset por el código numérico generado\n",
        "dataset['tag'] = dataset.tag.apply(lambda x: tag_to_code[x])\n",
        "\n",
        "# Primero las palabras se agrupan por la sentencia a la que pertenecen\n",
        "# Cada grupo se transforma en una lista y luego se convierte en un array de numpy\n",
        "dff = dataset.groupby(\"sentence_idx\")[['lemma','tag']].agg(list).applymap(np.asarray)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53KnuIp8Yj4v",
        "cell_id": "00052-c5fdce9c-2f19-4766-8bea-5ced5dfb4fd9",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "## 2.b) Distribuciones.\n",
        "\n",
        "Ahora que ya tenemos las sentencias codificadas y agrupadas, explore el tamaño de estas, en número de lemmas: ¿Son todas las sentencias de igual tamaño? ¿Le hace sentido esto? ¿Las redes que conoce pueden manajar ejemplos de distintos tamaños, y si pueden qué problemas podría traer? ¿Están las clases repartidas de manera equitativa?\n",
        "\n",
        "**Respuesta:** No son sentencias del mismo tamaño, esto tiene sentido pues en la práctica no se trabajará con sentencias de un mismo largo.\n",
        "Al momento de entrenar RNN's es necesaro definir la forma del input, sin embargo estas no dependen del largo de la secuencia a la hora de inferir.\n",
        "Los problemas que esto podría tener ocurren en el entrenamiento, cuando no exista un calce perfecto entre el tamaño de cada input con el largo total\n",
        "de la secuencia de forma que en algún momento se deba alimentar la red con un input de dimensiones distintas, en estos casos se puede **truncar** o utilizar **padding**.\n",
        "\n",
        "Las clases no están repartidas de manera equitativa, sentencias con un largo de aproximadamente 20 palabras están sobrerepresentadas.\n",
        "\n",
        "\n",
        "Estudie la distribución del largo de los textos a procesar. Estudie también la frecuencia con la que aparecen las palabras en todo el dataset. **¿Se observa una ley Zipf?** (https://es.wikipedia.org/wiki/Ley_de_Zipf). Realice un gráfico de la cantidad de datos por clase. Comente.\n",
        "\n",
        "**Respuesta:** Efectivamente podemos observar la ley Zipf. Esto se evidencia en nuestro último gráfico de esta sección, donde vemos que\n",
        "al graficar los lemas según su frecuencia de mayor a menor obtenemos una función con el mismo comportamiento que una de la forma $\\displaystyle f(x) = \\frac{1}{x^a}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4njiLpNgbWf",
        "cell_id": "00053-05e7d9ec-6051-411e-98e8-2983edaa1ddb",
        "output_cleared": false,
        "source_hash": "b85f3bf5",
        "execution_millis": 21,
        "execution_start": 1609303039793,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b71056-0301-4818-810f-400810160a6a"
      },
      "source": [
        "print(n_lemmas)\n",
        "n_tags = len(tag_to_code)\n",
        "print(n_tags)\n",
        "#print(dff['lemma'].applymap(len))\n",
        "largos_sentencias = list(map(len,dff['lemma'].tolist() ))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20243\n",
            "17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00072-e503696e-bbca-43db-add5-df057f61925e",
        "output_cleared": false,
        "source_hash": "38b7a750",
        "execution_millis": 622,
        "execution_start": 1609301138439,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "SahTPgrnz0AW",
        "outputId": "af229eb4-1525-4918-9679-ceaa4f6f312e"
      },
      "source": [
        "plt.hist(largos_sentencias,bins=100)\n",
        "plt.show()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00076-5278bf8d-424a-4f6a-aab9-23c2f0c490e8",
        "output_cleared": false,
        "source_hash": "19942562",
        "execution_millis": 654,
        "execution_start": 1609303046075,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "bUv2pgSBz0AW",
        "outputId": "f108b715-555d-4581-8499-23dd38092e87"
      },
      "source": [
        "%matplotlib inline\n",
        "lemma_frequence_2 = pd.Series(np.concatenate([x for x in dff[\"lemma\"]])).value_counts().sort_index()\n",
        "#plt.hist(lemma_frequence_2.values,bins = lemma_frequence_2.index.map(str))\n",
        "#plt.hist(lemma_frequence_2.values, bins = lemma_frequence_2.index.to_numpy())\n",
        "lemma_frequence_2.plot(figsize=(10,10))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f40319fa128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgloVFFBYkZQ",
        "cell_id": "00054-7cb457f8-688f-4cde-ad92-a6a365843d63",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "## 2.c) Padding y one hot vectors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozrWCFFtjAcs",
        "cell_id": "00055-ea03ea6e-9660-4944-a6ad-06154392504d",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "##### I) En esta parte de la tarea, deben lograr que todas las secuencias de lemmas (y los tags correspondientes) queden del mismo largo, es decir realizar padding. El padding debe realizarse con el valor 0, pueden escoger si realizarlo al comienzo de la secuencia o al final, expliquen su elección. Pueden utilizar la función keras.preprocessing.sequence.pad_sequences o escribir sus propios códigos. Elija un valor de maxlen que le parezca adecuado.\n",
        "**Respuesta:**\n",
        "\n",
        "\n",
        "**Post padding:** En el inglés, español y otros lenguajes, gramaticalmente las entidades\n",
        "suelen ser nombradas al principio de las sentencias, por ejemplo, \"La organización logró sus\n",
        "objetivos este año\". Por lo anterior, nos deberíamos asegurar que las neuronas que reciben\n",
        "la parte inicial de las sentencias trabajen con datos válidos.  \n",
        "\n",
        "\n",
        "\n",
        "¿Opinan que es deseable utilizar el valor 0 como codificación de palabras que \"no existen\", o creen que es irrelevante por ejemplo que su valor sea 1?\n",
        "\n",
        "**Respuesta:**  \n",
        "Es deseable dependiendo del diccionario, en nuestro caso la codificación numérica\n",
        "de los lemmas parte desde el 1, por lo que, al hacer padding debemos evitar\n",
        "utilizar un número que sea parte de los lemmas, ya que, en ese caso estaríamos añadiendo\n",
        "palabras con significado a la sentencia, al utilizar el 0 que no es parte de diccionario\n",
        "estamos añadiendo un elemento neutro."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00078-34d377d2-897d-409b-a33b-989ba3ab8e16",
        "output_cleared": false,
        "source_hash": "c351ef82",
        "execution_millis": 6,
        "execution_start": 1609303050220,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojkqx1Ajz0AY",
        "outputId": "2606fc33-65d7-4630-9923-fafaa4cbc546"
      },
      "source": [
        "mean_sentencias = sum(largos_sentencias)/len(largos_sentencias)\n",
        "print(mean_sentencias)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29.871620661227507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-8M5Ql4YnK7",
        "cell_id": "00056-c6cb74e9-f856-4a2d-a309-4bc225dd077a",
        "output_cleared": false,
        "source_hash": "8a35d3ba",
        "execution_millis": 324,
        "execution_start": 1609303052211,
        "deepnote_cell_type": "code"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "max_len = 30  # Promedio de largos de secuencias\n",
        "X = pad_sequences(dff['lemma'], maxlen=max_len,padding='post') # 0 al inicio por default\n",
        "Y = dff['tag'].values\n",
        "Y = pad_sequences(Y, maxlen=max_len,padding='post') # 0 al inicio por default"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW3uZVNnYnoz",
        "cell_id": "00057-7dffa017-8127-4d55-9e91-91c97e12fc9a",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "##### II) Para poder entregar una clasificación sobre los distintos *tags* es necesario transformarlos a *one hot vectors*, debido a que están codificados en números enteros, esto resultará en un arreglo tridimensional con la cantidad de ejemplos, la cantidad máxima de palabras y la cantidad de posibles *tags*. Luego de esto cree los conjuntos de entrenamiento y de prueba con el código a continuación **¿Cuáles son las dimensiones de entrada y salida de cada conjunto?** Comente\n",
        "\n",
        "**Dimensiones de entrada:** Para el conjunto de entrenamiento tenemos 26382 ejemplos y para validar tenemos 8795 , donde cada uno es un arreglo de 30 lemmas, es decir,\n",
        "una sentencia codificada numéricamente.  \n",
        "**Dimensiones de salida:**  Para el conjunto de entrenamiento tenemos 26382 ejemplos y para validar tenemos 8795 , donde cada elemento de salida es un arreglo con la\n",
        "sentencia completa, que a su vez cada elemento de la sentencia tiene asociado un arreglo de dimensión 18 (debería ser 17, pero por un error de keras se sumo 1 al largo del one-hot-vector),\n",
        "el cual tiene en el elemento $i$ la probabilidad de que ese lemma sea de la clase/tag $i$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSZsy681jQgl",
        "cell_id": "00058-f874c39a-ba17-4a18-813c-cb137ca509c6",
        "output_cleared": false,
        "source_hash": "45f0f395",
        "execution_millis": 1138,
        "execution_start": 1609303058126,
        "deepnote_cell_type": "code"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "y = np.asarray([to_categorical(i, num_classes=n_tags + 1) for i in Y])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00081-9d9b7e9b-90df-470d-b1ae-7475bea7f58a",
        "output_cleared": false,
        "source_hash": "3b72bdac",
        "execution_millis": 46,
        "execution_start": 1609303060660,
        "deepnote_cell_type": "code",
        "id": "0Tkppofnz0Aa"
      },
      "source": [
        "x_tr, x_val, y_tr, y_val = train_test_split(X, y, test_size=0.25, random_state=1)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCwsCeU922BV",
        "cell_id": "00059-b365c453-9e4d-438d-8336-958b33f8dcaa",
        "output_cleared": false,
        "source_hash": "311180c9",
        "execution_millis": 0,
        "execution_start": 1609301141176,
        "deepnote_cell_type": "code",
        "outputId": "0b07cdc4-5ddf-4891-9f12-29c825be492c"
      },
      "source": [
        "x_tr.shape,y_tr.shape,x_val.shape,y_val.shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((26382, 30), (26382, 30, 18), (8795, 30), (8795, 30, 18))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfliTCJkYo8D",
        "cell_id": "00060-3f093086-4df4-4120-aed2-e76865db790d",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "## 2.d) RNN many to many\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23LOn_CJoKJh",
        "cell_id": "00061-d4d80cf7-5f73-4b33-bb38-72d2261ad085",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "\n",
        "##### I) Defina una red neuronal recurrente *many to many* con compuertas LSTM para aprender a *tagear* la entidad en el texto, entrene y evalúe su desempeño sobre ambos conjuntos. Esta red debe procesar la secuencia de *lemmas* rellenados (o sin rellenar) y entregar el *tag* a cada uno de los *lemmas*, por lo que la salida de la red no es un vector como anteriormente se ha trabajado, sino que tiene una dimensión extra la cual es debido a que en cada instante de tiempo se necesita entregar un *output*. Como los *lemmas* corresponden a datos esencialmente categóricos, o al menos discretos, es necesario generar una representación vectorial de ellas. La primera capa de la red a construir debe por lo tanto incluir una transformación entrenable desde el espacio de representación original (discreto) a ${\\rm I\\!R}^{d}$ , con $d$ la dimensionalidad del *embedding*. **Comente sobre los cambios que sufre un dato al ingresar a la red y la cantidad de parámetros de la red**.\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "1. Input -> [30].\n",
        "2. Embedding -> [30, 32]\n",
        "3. LSTM -> [30, 128]\n",
        "4. Dense -> [30,18]\n",
        "\n",
        "\n",
        "Al ingresar una secuencia al embedding, cada lemma de la secuencia se lleva a una representación vectorial de 32 dimensiones, por lo que, la salida es una secuencia de largo 30\n",
        "donde cada elemento es un vector de 32. Esta secuencia alimenta a la LSTM, la cual retorna una secuencia de 30 elementos (return_sequences=True), donde cada \n",
        "elemento tiene el output de las 128 celdas de la LSTM. Finalmente esto alimenta a la capa densa, la que devuelve la secuencia de 30 elementos, donde cada elemento \n",
        "es un vector de largo 18 (17+1), donde el elemento $i$ del vector representa la probabilidad del lemma de ser del tag $i$. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNsItCWwYpsp",
        "cell_id": "00062-a2f5108d-1298-4145-bf4e-d575f7c6448d",
        "output_cleared": false,
        "source_hash": "8ef688d8",
        "execution_millis": 476,
        "execution_start": 1609303090990,
        "deepnote_cell_type": "code"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding, Dense\n",
        "x_tr = np.asarray(x_tr).astype('float32')\n",
        "x_val = np.asarray(x_val).astype('float32')\n",
        "max_len = 30\n",
        "\n",
        "#¿problemas con el embedding al ejecutar? chequear que el n_lemas, n_tags, y max_len correspondan a los datos modificados con padding\n",
        "m = Sequential()\n",
        "embedding_dim = 32\n",
        "m.add(Embedding(input_dim=n_lemmas+1, output_dim=embedding_dim, input_length=max_len))\n",
        "m.add(LSTM(units=128,return_sequences=True))\n",
        "m.add(Dense(n_tags+1, activation='softmax'))\n",
        "m.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])\n",
        "#history = m.fit(x_tr,y_tr, validation_data=(x_val,y_val), epochs=3, batch_size=128)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00025-30f4b825-8364-4fb0-827b-6c0b8d44d60d",
        "output_cleared": false,
        "source_hash": "3c51ff54",
        "execution_millis": 12,
        "execution_start": 1609301141565,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej_QLAGpz0Ad",
        "outputId": "b72fe88b-eb8d-4757-ccc3-d3e4410872ee"
      },
      "source": [
        "m.summary()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 30, 32)            647808    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 30, 128)           82432     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 30, 18)            2322      \n",
            "=================================================================\n",
            "Total params: 732,562\n",
            "Trainable params: 732,562\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00025-cdc0c82f-dc73-4612-a29d-5ee95b1156bb",
        "output_cleared": false,
        "source_hash": "fa39918e",
        "execution_millis": 9,
        "execution_start": 1609301141582,
        "deepnote_cell_type": "code",
        "id": "noWVSvPOz0Ad"
      },
      "source": [
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2PBG8pB3Ty6"
      },
      "source": [
        "#pip install sklearn-crfsuite"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd6E8NBrYqp1",
        "cell_id": "00063-b3d33cb9-8dab-47d3-9868-0c0faf32b9c0",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "Para evaluar su modelo utilice una métrica adecauda para el desbalance presente entre las clases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvPOBSNVYrII",
        "cell_id": "00064-d5b97218-2801-43b7-a0fe-e8d832131cc6",
        "output_cleared": false,
        "source_hash": "818ff6ce",
        "execution_millis": 5075,
        "execution_start": 1609301141596,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2788af9-239b-4b18-a143-e8941fd39998"
      },
      "source": [
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "\n",
        "  \n",
        "y_pred = m.predict(x_val)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "\n",
        "print(flat_classification_report(y_val,y_pred))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91    152888\n",
            "           1       0.98      0.91      0.94    206567\n",
            "           2       0.84      0.49      0.62      8734\n",
            "           3       0.99      0.09      0.16      3771\n",
            "           4       0.82      0.19      0.30      3633\n",
            "           5       0.71      0.12      0.21      1700\n",
            "           6       0.00      0.00      0.00      4577\n",
            "           7       0.00      0.00      0.00      3712\n",
            "           8       0.95      0.49      0.65      4643\n",
            "           9       0.00      0.00      0.00        83\n",
            "          10       0.00      0.00      0.00        55\n",
            "          11       0.63      0.56      0.60      3717\n",
            "          12       0.00      0.00      0.00        43\n",
            "          13       1.00      0.03      0.06      1409\n",
            "          14       0.00      0.00      0.00        60\n",
            "          15       0.00      0.00      0.00        84\n",
            "          16       0.00      0.00      0.00        76\n",
            "          17       0.00      0.00      0.00        23\n",
            "\n",
            "   micro avg       0.92      0.87      0.89    395775\n",
            "   macro avg       0.43      0.21      0.25    395775\n",
            "weighted avg       0.91      0.87      0.87    395775\n",
            " samples avg       0.87      0.87      0.87    395775\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbvzZFGrYrnB",
        "cell_id": "00065-0c53110e-240a-45ce-bcc2-cf8e334d545e",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "##### II) Varı́e la dimensionalidad del embedding inicial y determine si **aumenta o disminuye el error de clasificación**. Comente.\n",
        "\n",
        "**Respuesta:** Al experimentar con dimensionalidades mayores a 30 para el embedding no obtenemos una mejora considerable basandonos en la\n",
        "precisión por weighted average. Con una dimensionalidad de 25 obtenemos resultados practicamente iguales a los obtenidos con 30, sin embargo\n",
        "al comenzar a disminuir aún más la dimensionalidad del embeddng obtenemos peores resultados. Esto es claro pues \n",
        "estamos reduciendo en exceso la dimensionalidad de la representación matemática de nuestro vocabulario (lemmas), por lo que, la capa de embedding no logra aprender\n",
        "todos los patrones entre los lemmas del dataset, es decir, desde cierta dimensión hacia abajo aparece un problema de underfitting del vocabulario utilizado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "899gszmeFCPU",
        "cell_id": "00066-8f80bbd1-5567-43b3-af36-185dac1c301a",
        "output_cleared": false,
        "source_hash": "4512b569",
        "execution_millis": 83358,
        "execution_start": 1609301146687,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "165ea358-ffa1-4cda-a92d-481c5fbae06f"
      },
      "source": [
        "#¿problemas con el embedding al ejecutar? chequear que el n_lemas, n_tags, y max_len correspondan a los datos modificados con padding\n",
        "m = Sequential()\n",
        "embedding_dim = 25\n",
        "m.add(Embedding(input_dim=n_lemmas+1, output_dim=embedding_dim, input_length=max_len))\n",
        "m.add(LSTM(units=128,return_sequences=True))\n",
        "m.add(Dense(n_tags+1, activation='softmax'))\n",
        "m.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])\n",
        "history = m.fit(x_tr,y_tr, validation_data=(x_val,y_val), epochs=3, batch_size=128)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "207/207 [==============================] - 5s 16ms/step - loss: 1.4532 - acc: 0.7412 - val_loss: 0.4648 - val_acc: 0.8822\n",
            "Epoch 2/3\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.3986 - acc: 0.8913 - val_loss: 0.2957 - val_acc: 0.9137\n",
            "Epoch 3/3\n",
            "207/207 [==============================] - 3s 14ms/step - loss: 0.2712 - acc: 0.9232 - val_loss: 0.2270 - val_acc: 0.9433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00032-71426c83-714c-45fb-b0af-d5bc052f70b6",
        "output_cleared": false,
        "source_hash": "a9eb62c0",
        "execution_millis": 4895,
        "execution_start": 1609301230061,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDF0xlLiz0Ae",
        "outputId": "06c5d266-84e3-400b-9245-906729fabbdd"
      },
      "source": [
        "y_pred = m.predict(x_val)\n",
        "y_pred = (y_pred > 0.5) \n",
        "print(flat_classification_report(y_val,y_pred))#, labels=tag_to_code))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     54637\n",
            "           1       0.97      0.98      0.98    178340\n",
            "           2       0.86      0.52      0.65      7537\n",
            "           3       0.99      0.12      0.21      3143\n",
            "           4       0.82      0.22      0.34      3033\n",
            "           5       0.72      0.13      0.22      1482\n",
            "           6       0.00      0.00      0.00      3821\n",
            "           7       0.00      0.00      0.00      3139\n",
            "           8       0.96      0.58      0.72      4017\n",
            "           9       0.00      0.00      0.00        68\n",
            "          10       0.00      0.00      0.00        44\n",
            "          11       0.82      0.57      0.67      3121\n",
            "          12       0.00      0.00      0.00        33\n",
            "          13       1.00      0.03      0.06      1228\n",
            "          14       0.00      0.00      0.00        50\n",
            "          15       0.00      0.00      0.00        72\n",
            "          16       0.00      0.00      0.00        64\n",
            "          17       0.00      0.00      0.00        21\n",
            "\n",
            "   micro avg       0.97      0.91      0.94    263850\n",
            "   macro avg       0.45      0.23      0.27    263850\n",
            "weighted avg       0.94      0.91      0.91    263850\n",
            " samples avg       0.91      0.91      0.91    263850\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz961L05YwlU",
        "cell_id": "00067-f01e1031-9d8b-41c8-afa7-963b98f317a3",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "## 2.e) RNN Bidireccional y masking\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGsjPHI7GBFa",
        "cell_id": "00068-0e57f2f6-839f-46d1-baca-7591e2cec47f",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "##### I) Algunos autores señalan la importante dependencia que existe en texto, no solo con las palabras anteriores, sino que con las que siguen.**Mejore la red definida en 2.d.I) utilizando una red neuronal recurrente Bidireccional**, es decir, con recurrencia en ambas direcciones sobre la secuencia de *lemmas* de entrada. Comente **cuál debiera ser la forma correcta de usar el parámetro *merge_mode*** (concatenar, multiplicar, sumar o promediar) para este caso. Además comente las transformaciones que sufre el patrón de entrada al pasar por las capas. **¿Mejora o empeora el desempeño?** Analice.\n",
        "\n",
        "\n",
        "La forma correcta (o con la que obtenemos mejor resultados) de utilizar el parametro merge_mode es sum. Esto debido a que como planteamos anteriormente la información más relevante la obtenemos con el paso del inicio al final (forward), \n",
        "de forma que si por ejemplo utilizamos mult y el pasado nos indica una probabilidad cercana a 1 mientras que el futuro (backward) una cercana a cero al hacer merge obtendremos un output cercano a cero. Al utilizar sum\n",
        "simplemente tomamos la probabilidad que nos indica el pasado (forward) para casos donde el futuro nos indica una probabilidad cercana a 0. Notar además que al utilizar concat no se descarta información debido a que no hacemos un merge como tal, de hecho se aumenta la dimensionalidad del output de la LSTM y la tarea de identificar las ponderaciones de importancia recae sobre la capa densa\n",
        "sin embargo para esta aplicación esto resulta en un gasto innecesario de recursos computacionales debido a \n",
        "\n",
        "\n",
        "Empeoro levemente el desempeño. En problemas como predecir la siguiente palabra en una sentencia, es realmente útil conocer el contexto futuro (lo que se espera decir\n",
        "después de la palabra a predecir), en cambio, en el problema de predicción de tipo de entidad, dada la forma en que estructuramos el lenguaje normalmente las palabras\n",
        "que utilizamos antes nos permiten reconocer con mayor facilidad una entidad que será nombrada. En el ejemplo 1, notamos como antes de mencionar **Hyde Park**\n",
        "se utiliza la palabra **in**, el cual es un patrón recurrente la momento de hablar de un lugar físico con ciertas características (en inglés), las palabras que\n",
        "aparecen después de **Hyde Park**, no son realmente utiles, ya que, son muy específicas, por lo que, no ayudarán a mejorar la capacidad de generalización del modelo.\n",
        "En el ejemplo 2, observamos lo mismo para **Britain's**, la palabra **of** es un patrón típico antes de mencionar un B-Geo, la misma regla puede ser aplicada para\n",
        "el resto de palabras en negritas, normalmente lo más importante para reconocer el tipo de una entidad está en el contexto pasado de la sentencia.  \n",
        "\n",
        "Ejemplos:\n",
        "   \n",
        "1. They marched from the houses of parliament to a rally in **Hyde Park**. Police put the number of marchers at 10.000...  \n",
        "2. the annual conference of **Britain's** ruling **Labor Party** in the **southern English** seaside resort of Brighton. The party is ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgiGfK4OYxB9",
        "cell_id": "00069-a10de634-fd40-4cdf-90fc-3eab7b1d424c",
        "output_cleared": false,
        "source_hash": "6e8becae",
        "execution_millis": 139470,
        "execution_start": 1609301234961,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20297bf0-a821-451a-9c0b-d72d31ad2431"
      },
      "source": [
        "from keras.layers import Bidirectional\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=n_lemmas + 1, output_dim=embedding_dim, input_length=max_len))\n",
        "layer_lstm = LSTM(units=128,return_sequences=True)\n",
        "model.add(Bidirectional(layer_lstm,merge_mode=\"concat\")) # 'sum', 'mul', 'concat', 'ave'\n",
        "model.add(Dense(n_tags + 1, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])\n",
        "history = model.fit(x_tr,y_tr, validation_data=(x_val,y_val), epochs=3, batch_size=128)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 30, 25)            506100    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 30, 256)           157696    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 30, 18)            4626      \n",
            "=================================================================\n",
            "Total params: 668,422\n",
            "Trainable params: 668,422\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "207/207 [==============================] - 7s 21ms/step - loss: 1.2446 - acc: 0.7559 - val_loss: 0.3945 - val_acc: 0.8862\n",
            "Epoch 2/3\n",
            "207/207 [==============================] - 3s 16ms/step - loss: 0.3403 - acc: 0.9000 - val_loss: 0.2329 - val_acc: 0.9350\n",
            "Epoch 3/3\n",
            "207/207 [==============================] - 3s 16ms/step - loss: 0.1984 - acc: 0.9452 - val_loss: 0.1616 - val_acc: 0.9548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00036-a2ddbc01-a653-4455-84b7-d29765c46fa9",
        "output_cleared": false,
        "source_hash": "6ca40ddf",
        "execution_millis": 6946,
        "execution_start": 1609301374436,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xGGFMIvz0Af",
        "outputId": "b614eb9c-118c-4bb4-bfda-29c35794086f"
      },
      "source": [
        "y_pred_2e = model.predict(x_val)\n",
        "y_pred_2e = (y_pred_2e > 0.5) \n",
        "print(flat_classification_report(y_val,y_pred_2e))#, labels=tag_to_code))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     54637\n",
            "           1       0.98      0.98      0.98    178340\n",
            "           2       0.86      0.69      0.76      7537\n",
            "           3       0.95      0.87      0.91      3143\n",
            "           4       0.83      0.54      0.66      3033\n",
            "           5       0.79      0.45      0.58      1482\n",
            "           6       0.90      0.18      0.30      3821\n",
            "           7       0.83      0.13      0.23      3139\n",
            "           8       0.92      0.72      0.81      4017\n",
            "           9       0.00      0.00      0.00        68\n",
            "          10       0.00      0.00      0.00        44\n",
            "          11       0.81      0.69      0.75      3121\n",
            "          12       0.00      0.00      0.00        33\n",
            "          13       0.81      0.37      0.50      1228\n",
            "          14       0.00      0.00      0.00        50\n",
            "          15       0.00      0.00      0.00        72\n",
            "          16       0.00      0.00      0.00        64\n",
            "          17       0.00      0.00      0.00        21\n",
            "\n",
            "   micro avg       0.97      0.94      0.96    263850\n",
            "   macro avg       0.54      0.37      0.42    263850\n",
            "weighted avg       0.97      0.94      0.94    263850\n",
            " samples avg       0.94      0.94      0.94    263850\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7Krl2BVYxox",
        "cell_id": "00070-4b43ebd9-984f-45c3-b5f2-259799500423",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "##### II) Recientemente se ha implementado la capa de *Masking* en las redes recurrentes en *keras*, lo cual podría traer gran ayuda gracias al *padding* que se realiza con el símbolo especial definido. Entrene la red definida en 2.d.I) y compare al utilizar esta funcionalidad de enmascarar el valor 0  en este caso para el default de la capa embedding.\n",
        "**Respuesta:** \n",
        "\n",
        "Al utilizar mask_zero = True obtenemos un peor desempeño, al parecer no nos sirve debido a que la aplicamos de forma errónea. Sin embargo, también podemos enmascarar el valor 0 agregando una capa Masking luego del Embedding, para este caso sí obtuvimos mejores resultados.\n",
        "\n",
        "Usando Masking obtenemos para el weighted average los valores 0.97, 0.96 y 0.96. Para el modelo de la pregunta 2.d.I obtenemos los valores 0.91, 0.87 y 0.87. \n",
        "\n",
        "Es de esperarse esta mejora debido a que a diferencia del modelo anterior, ahora no estamos tomando en cuenta los ceros introducidos por el padding en el aprendizaje, es decir estamos disminuyendo una fuente de error en los datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXC5XTgIYyKU",
        "cell_id": "00071-b64ae10e-991c-465d-bd94-92fd8294d4cc",
        "output_cleared": false,
        "source_hash": "62fef88b",
        "execution_millis": 107524,
        "execution_start": 1609301381383,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53fc591a-25ec-406f-ac32-c172b089b2bd"
      },
      "source": [
        "from keras.layers import Masking\n",
        "m_2e2 = Sequential()\n",
        "m_2e2.add(Embedding(input_dim=n_lemmas + 1, output_dim=embedding_dim))\n",
        "m_2e2.add(Masking(mask_value=0.0))\n",
        "m_2e2.add(LSTM(units=128,return_sequences=True))\n",
        "m_2e2.add(Dense(n_tags+1, activation='softmax'))\n",
        "m_2e2.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])\n",
        "history = m_2e2.fit(x_tr,y_tr, validation_data=(x_val,y_val), epochs=3, batch_size=128)"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "207/207 [==============================] - 13s 41ms/step - loss: 1.1027 - acc: 0.8324 - val_loss: 0.2714 - val_acc: 0.9259\n",
            "Epoch 2/3\n",
            "207/207 [==============================] - 7s 35ms/step - loss: 0.2342 - acc: 0.9354 - val_loss: 0.1548 - val_acc: 0.9591\n",
            "Epoch 3/3\n",
            "207/207 [==============================] - 7s 35ms/step - loss: 0.1330 - acc: 0.9644 - val_loss: 0.1176 - val_acc: 0.9669\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00039-ff8e6741-8a5c-4758-b76d-4941fe7b4772",
        "output_cleared": false,
        "source_hash": "d1dcbec8",
        "execution_millis": 6767,
        "execution_start": 1609301488915,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMTM1XVqz0Ag",
        "outputId": "3e5976fb-26b5-447a-eb6b-182145a49d68"
      },
      "source": [
        "y_pred_2e2 = m_2e2.predict(x_val)\n",
        "y_pred_2e2 = (y_pred_2e2 > 0.5) \n",
        "print(flat_classification_report(y_val,y_pred_2e2))#, labels=tag_to_code))"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    152888\n",
            "           1       0.97      0.99      0.98    206567\n",
            "           2       0.85      0.72      0.78      8734\n",
            "           3       0.96      0.87      0.91      3771\n",
            "           4       0.83      0.66      0.73      3633\n",
            "           5       0.85      0.49      0.62      1700\n",
            "           6       0.79      0.36      0.49      4577\n",
            "           7       0.75      0.36      0.49      3712\n",
            "           8       0.92      0.72      0.81      4643\n",
            "           9       0.00      0.00      0.00        83\n",
            "          10       0.00      0.00      0.00        55\n",
            "          11       0.83      0.83      0.83      3717\n",
            "          12       0.00      0.00      0.00        43\n",
            "          13       0.83      0.44      0.58      1409\n",
            "          14       0.00      0.00      0.00        60\n",
            "          15       0.00      0.00      0.00        84\n",
            "          16       0.00      0.00      0.00        76\n",
            "          17       0.00      0.00      0.00        23\n",
            "\n",
            "   micro avg       0.98      0.96      0.97    395775\n",
            "   macro avg       0.53      0.41      0.46    395775\n",
            "weighted avg       0.97      0.96      0.96    395775\n",
            " samples avg       0.96      0.96      0.96    395775\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph_Bc4mIYyiA",
        "cell_id": "00072-d092b646-5cdc-4f3b-987c-c90812bd43cc",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "## 2.f) Mejora libre\n",
        "\n",
        "En base a lo experimentado, **intente mejorar el desempeño de las redes encontradas**, ya sea utilizando y combinando las distintas variaciones que se hicieron en los distintos ítemes, como bien alguna mejora en el pre-proceso de los datos (largo de secuencia, el tipo de *padding* o alguna otra), agregar mayor profundidad, variar el número de unidades/neuronas, utilizando otra *gate* de recurrencia (GRU o Vanilla/Simple), en https://keras.io/layers/recurrent/,  entre otras. Utilice la red entrenada, **se espera que sea la mejor de esta sección**, y **muestre las predicciones**, el *NER tager*, sobre algún ejemplo de pruebas, comente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00041-47888ebc-45ac-41ab-8e13-f13752d98a0c",
        "output_cleared": false,
        "source_hash": "d518617f",
        "execution_millis": 1009,
        "execution_start": 1609303114218,
        "deepnote_cell_type": "code",
        "id": "UBwKL3Nkz0Ag"
      },
      "source": [
        "mean_sentencias = sum(largos_sentencias)/len(largos_sentencias)\n",
        "std = np.std(largos_sentencias)\n",
        "max_len = round(mean_sentencias + std.item())   # Promedio de largos de secuencias\n",
        "X = pad_sequences(dff['lemma'], maxlen=max_len,padding='pre') # 0 al inicio por default\n",
        "#X\n",
        "Y = dff['tag'].values\n",
        "Y = pad_sequences(Y, maxlen=max_len,padding='pre') # 0 al inicio por default\n",
        "y = np.asarray([to_categorical(i, num_classes=n_tags + 1) for i in Y])\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(X, y, test_size=0.25, random_state=1)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve0eznL28D2u",
        "cell_id": "00073-2c90f25f-1e1b-450c-9d68-408d63174bca",
        "output_cleared": false,
        "source_hash": "514a96c6",
        "execution_millis": 102998,
        "execution_start": 1609303120478,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59730ac3-06d1-4460-a929-adfd43e18619"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "from keras.layers import Embedding, Dense, GRU\n",
        "m_2f1 = Sequential()\n",
        "m_2f1.add(Embedding(input_dim=n_lemmas+1, output_dim=embedding_dim, input_length=max_len))##,mask_zero=True))\n",
        "m_2f1.add(GRU(units=128,return_sequences=True))\n",
        "m_2f1.add(Dense(n_tags+1, activation='softmax'))\n",
        "m_2f1.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])\n",
        "history = m_2f1.fit(x_tr,y_tr, validation_data=(x_val,y_val), epochs=3, batch_size=128)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "207/207 [==============================] - 5s 17ms/step - loss: 1.3249 - acc: 0.7191 - val_loss: 0.2933 - val_acc: 0.9198\n",
            "Epoch 2/3\n",
            "207/207 [==============================] - 3s 14ms/step - loss: 0.2487 - acc: 0.9317 - val_loss: 0.1708 - val_acc: 0.9536\n",
            "Epoch 3/3\n",
            "207/207 [==============================] - 3s 14ms/step - loss: 0.1501 - acc: 0.9597 - val_loss: 0.1282 - val_acc: 0.9651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00043-144038d7-3b8b-45d8-9b57-19a0ebb8dceb",
        "output_cleared": false,
        "source_hash": "e3806623",
        "execution_millis": 6139,
        "execution_start": 1609303260186,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFl42XGiz0Ah",
        "outputId": "23c6d2b8-5dd1-4e29-bf4b-c8ffdeb3dd74"
      },
      "source": [
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "y_pred_2f1 = m_2f1.predict(x_val)\n",
        "y_pred_2f1 = (y_pred_2f1 > 0.5) \n",
        "print(flat_classification_report(y_val,y_pred_2f1))#, labels=tag_to_code))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    152888\n",
            "           1       0.97      0.99      0.98    206567\n",
            "           2       0.83      0.75      0.79      8734\n",
            "           3       0.96      0.86      0.91      3771\n",
            "           4       0.88      0.47      0.62      3633\n",
            "           5       0.88      0.41      0.56      1700\n",
            "           6       0.92      0.24      0.38      4577\n",
            "           7       0.89      0.16      0.27      3712\n",
            "           8       0.92      0.74      0.82      4643\n",
            "           9       0.00      0.00      0.00        83\n",
            "          10       0.00      0.00      0.00        55\n",
            "          11       0.84      0.72      0.78      3717\n",
            "          12       0.00      0.00      0.00        43\n",
            "          13       0.90      0.36      0.52      1409\n",
            "          14       0.00      0.00      0.00        60\n",
            "          15       0.00      0.00      0.00        84\n",
            "          16       0.00      0.00      0.00        76\n",
            "          17       0.00      0.00      0.00        23\n",
            "\n",
            "   micro avg       0.98      0.95      0.97    395775\n",
            "   macro avg       0.55      0.37      0.42    395775\n",
            "weighted avg       0.97      0.95      0.96    395775\n",
            " samples avg       0.95      0.95      0.95    395775\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00044-0f0647bb-6513-4e69-b737-f8bc890210d2",
        "output_cleared": false,
        "source_hash": "d5aba270",
        "execution_millis": 0,
        "execution_start": 1609303870174,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBqZY2I3z0Ah",
        "outputId": "6e0571ae-c8e0-4b4d-db6a-937454688c3e"
      },
      "source": [
        "# 221\n",
        "example = 211\n",
        "pred_form = [np.where(x == True)[0][0]-1 if len(np.where(x == True)[0]) else 0 for x in y_pred_2f1[example]]\n",
        "for i in range(len(x_val[example])):\n",
        "    if x_val[example][i]==0:\n",
        "        continue\n",
        "    print(f'El tag predecido para el lemma {lemmas[x_val[example][i]-1]} es: {tags[pred_form[i]]}')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El tag predecido para el lemma on es: O\n",
            "El tag predecido para el lemma sunday es: B-tim\n",
            "El tag predecido para el lemma , es: O\n",
            "El tag predecido para el lemma the es: O\n",
            "El tag predecido para el lemma u.s. es: B-geo\n",
            "El tag predecido para el lemma militari es: O\n",
            "El tag predecido para el lemma said es: O\n",
            "El tag predecido para el lemma it es: O\n",
            "El tag predecido para el lemma had es: O\n",
            "El tag predecido para el lemma kill es: O\n",
            "El tag predecido para el lemma 15 es: O\n",
            "El tag predecido para el lemma to es: O\n",
            "El tag predecido para el lemma 20 es: O\n",
            "El tag predecido para el lemma suspect es: O\n",
            "El tag predecido para el lemma taleban es: B-org\n",
            "El tag predecido para el lemma fighter es: O\n",
            "El tag predecido para el lemma in es: O\n",
            "El tag predecido para el lemma an es: O\n",
            "El tag predecido para el lemma airstrik es: O\n",
            "El tag predecido para el lemma after es: O\n",
            "El tag predecido para el lemma coalit es: O\n",
            "El tag predecido para el lemma forc es: O\n",
            "El tag predecido para el lemma came es: O\n",
            "El tag predecido para el lemma under es: O\n",
            "El tag predecido para el lemma small es: O\n",
            "El tag predecido para el lemma arm es: O\n",
            "El tag predecido para el lemma and es: O\n",
            "El tag predecido para el lemma rocket es: O\n",
            "El tag predecido para el lemma fire es: O\n",
            "El tag predecido para el lemma . es: O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l24Zv52IYzXV",
        "cell_id": "00074-44e0d0da-1a22-48c5-b73f-0c056a5bcdc7",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "## 2.g) Escribamos palabras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-5OjLw5826S",
        "cell_id": "00075-f8af08db-f805-45a5-9f43-f1ae6d1d95b3",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "##### I) Ahora buscaremos otra aplicación a las redes recurrentes, predecir el caracter siguiente. Si logramos entrenar una red que sea buena en esta tarea, podremos escribir texto automáticamente, pues podemos, a partir de una frase, predecir el caracter siguiente, y luego introducir la nueva frase sin el primer caracter en la red nuevamente, e iterando así escribir automáticamente. Si bien las redes recurrentes son adecuadas para esta tarea, no pretendemos entrenar un Shakespeare en esta tarea, sin embargo es interesante investigar qué tan verosimil o no puede lograr ser el texto generado.\n",
        "\n",
        "Para esto, primero crearmos nuestro nuevo dataset. Para esta tarea preferiremos unir todas las frases en un solo gran corpus y luego crear nuevas secuencias semi redundantes. Esto nos evita primero el problema de tener que hacer padding, pues crearemos todas las entradas iguales, pero también nos permite aprovechar mejor el dataset, de cierta forma aumentando el número de datos. El target en este caso será solo el caracter siguiente correspondiente a cada secuencia.\n",
        "\n",
        "En este item debe cargar el dataset. **Explique lo que hace el código entregado**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDLrAoVP8iXA",
        "cell_id": "00076-f9c99967-afba-4a3d-a9d5-3789feab9235",
        "output_cleared": false,
        "source_hash": "14ebedd1",
        "execution_millis": 8536,
        "deepnote_to_be_reexecuted": false,
        "execution_start": 1609354282340,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da6ecc24-a744-4d24-ad39-a3f45e5ffcb5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "# Cargamos el dataframe\n",
        "df_w = pd.read_csv(os.path.join(\"ner.csv\"), engine='python', error_bad_lines=False)\n",
        "# Elimina todos los registros con valores nan y toma la columna word\n",
        "df_w = df_w.dropna()[['word']]\n",
        "\n",
        "corpus = ' '.join(list(df_w.word.values)).lower() #unimos todas las \"palabras\" en minuscula en un gran string\n",
        "sentence_length = 40 # definimos el largo de la secuencia\n",
        "steps = 5 # definimos el salto entre sentencia y sentencia, como es menor que 40 iremos repitiendo caracteres\n",
        "\n",
        "# Lista para guardas las sentencias\n",
        "sentences = []\n",
        "# Lista para guardar los caracteres siguientes\n",
        "next_char = []\n",
        "# Itera sobre el corpus que contiene todas las palabras en minúscula con pasos de a 5 palabras\n",
        "for i in range(0,len(corpus) - sentence_length - 1 , steps):\n",
        "  # Arma las sentencias con el largo de la sentencia definido previamente, se destaca que, al ser el largo de las secuencias mayor que el step, cada secuencia\n",
        "  # contendrá palabras repetidas de sentencias anteriores\n",
        "  sentences.append(corpus[i:sentence_length+i])  \n",
        "  # Se añade el siguiente caracter de la secuencia recién añadida, es decir, el valor a predecir\n",
        "  next_char.append(corpus[sentence_length+i]) \n",
        "\n",
        "# Codificamos cada caracter presente en el corpus\n",
        "chars_to_code = {char:code for code, char in enumerate(set(corpus))} \n",
        "# Decodificamos cada codigo al caracter correspondiente\n",
        "code_to_chars = {code:char for char,code in chars_to_code.items()}\n",
        "# Codificamos cada sentencia de entrenamiento\n",
        "x = np.array([[chars_to_code[char] for char in sentence] for sentence in sentences])\n",
        "# Codificamos cada caracter de output para una sentencia en específico\n",
        "y = np.array([chars_to_code[char] for char in next_char])\n",
        "# Pasamosa a one hot vector las predicciones\n",
        "y = to_categorical(y)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping line 281837: Expected 25 fields in line 281837, saw 34\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WNuNY2i8oUz",
        "cell_id": "00077-d599f486-9d9b-4568-8e35-e65e7f8de580",
        "output_cleared": false,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "##### II) Entrene ahora una red con estos datos utilizando GRU. El resto de la estructura queda a su elección. Evalúe el desempeño de su red evaluando qué tan bien genera texto, puede utilizar las funciones propuestas como callback para ver como progresa su red. Pruebe a lo menos 2 estructuras distintas.\n",
        "\n",
        "Una vez esté satisfecho de su red, hágala escribir algunos textos a partir de textos semilla elegidos por usted. Describa sus observaciones. ¿Qué cree ocurriría si entrenamos la red con otro dataset?\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "Los textos generados para una misma secuencia inicial serían distintos. Esto debido a que en el aprendizaje se aprenderán \n",
        "relaciones distintas, obteniendo así modelos que se comportan de forma distinta frente a un mismo output. Por ejemplo, si entrenamos un modelo\n",
        "con un dataset de opiniones de peliculas, es de esperarse que los textos generados se basen principalmente en nombre de actriz, actores, peliculas, personajes, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEQzpcMV85a_",
        "cell_id": "00078-f13ef65d-98df-4a5b-b94e-5d495ea31545",
        "output_cleared": false,
        "source_hash": "80b65a9d",
        "execution_millis": 5667,
        "execution_start": 1609302978612,
        "deepnote_cell_type": "code"
      },
      "source": [
        "from keras.layers import Embedding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import GRU\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "\n",
        "def predict_char(model, sentence):\n",
        "    x = [chars_to_code[char] for char in sentence]\n",
        "    x = pad_sequences([x], maxlen=sentence_length, padding='pre', value=0)\n",
        "    probas = model.predict(x)[0]\n",
        "    next_index = np.random.choice(len(chars_to_code), p=probas)\n",
        "    return code_to_chars[next_index]\n",
        "\n",
        "def on_epoch_end(epoch, logs):\n",
        "    print(f'\\n Generating random text for epoch: {epoch}')\n",
        "    start_index = random.randint(0,x.shape[0]-1)\n",
        "    sentence = ''.join([code_to_chars[code] for code in x[start_index]])\n",
        "    print('\\n Generating with seed: ' + sentence)\n",
        "    sys.stdout.write(sentence)\n",
        "    for i in range(400):\n",
        "        next_char = predict_char(character, sentence)\n",
        "        sentence = sentence[1:] + next_char #for next character\n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    return\n",
        "\n",
        "print_text_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqLb5kym9JRM",
        "cell_id": "00079-d3581d9c-9b22-4475-be76-1cab52b37e48",
        "output_cleared": false,
        "source_hash": "8111c4c8",
        "execution_millis": 845939,
        "execution_start": 1609302079624,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecdc31b4-91b0-4866-9305-721a2b38402d"
      },
      "source": [
        "character = Sequential()\n",
        "embedding_dim = 100\n",
        "character.add(Embedding(input_dim=y.shape[1], output_dim=embedding_dim, input_length=x.shape[1]))\n",
        "character.add(GRU(128,return_sequences=False))\n",
        "character.add(Dense(y.shape[1],activation='softmax'))\n",
        "optimizer = RMSprop(lr = 0.01)\n",
        "character.compile(loss='categorical_crossentropy', optimizer=optimizer,metrics=[\"acc\"])\n",
        "character.fit(x,y, epochs=1, batch_size = 512,callbacks=[print_text_callback])\n",
        "character.summary()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2371/2371 [==============================] - 30s 12ms/step - loss: 1.8508 - acc: 0.4604\n",
            "\n",
            " Generating random text for epoch: 0\n",
            "\n",
            " Generating with seed: pine army camp , where u.s. soldiers and\n",
            "pine army camp , where u.s. soldiers and fcoccement obchunters forced officiancens stand dri . decupted due willed days will near days on during friday porsman jodes for gaymaks say decoup , and forly misio has and killed stands wednsund fives elutivened trand to overivers three on tued injasas killed in legged tile runs officials mud days in the cancem for the terrists for nissing for dismonth in onew af quccad say that culoods jontiveModel: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 40, 100)           6000      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 128)               88320     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 60)                7740      \n",
            "=================================================================\n",
            "Total params: 102,060\n",
            "Trainable params: 102,060\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00050-636c1aac-e64e-4912-bd28-dcaa77151214",
        "output_cleared": false,
        "source_hash": "9f5f0a31",
        "execution_millis": 708,
        "execution_start": 1609302989132,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZaIV7_Zz0Aj",
        "outputId": "50d6236d-c85b-4ecd-e310-3d566bbf1359"
      },
      "source": [
        "predicted_char = \"the flowers are\"\n",
        "for i in range(100):\n",
        "    predicted_char = predicted_char + predict_char(character,predicted_char)\n",
        "print(predicted_char)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the flowers are mites for the dispressments in the gensons the outside fund days of the glans thats fromer bringin \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00051-43a0ddbb-4be5-4cfc-8ce1-a04b736a5e44",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYbeluE6z0Aj",
        "outputId": "283974fa-4db1-4c20-9089-ad98c8267130"
      },
      "source": [
        "character_2 = Sequential()\n",
        "embedding_dim = 100\n",
        "character_2.add(Embedding(input_dim=y.shape[1], output_dim=embedding_dim, input_length=x.shape[1]))\n",
        "character_2.add(GRU(32,return_sequences=True))\n",
        "character_2.add(GRU(128,return_sequences=False))\n",
        "character_2.add(Dense(y.shape[1],activation='softmax'))\n",
        "optimizer = RMSprop(lr = 0.01)\n",
        "character_2.compile(loss='categorical_crossentropy', optimizer=optimizer,metrics=[\"acc\"])\n",
        "character_2.fit(x,y, epochs=2, batch_size = 512)\n",
        "character_2.summary()"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "2371/2371 [==============================] - 37s 15ms/step - loss: 1.8973 - acc: 0.4475\n",
            "Epoch 2/2\n",
            "2371/2371 [==============================] - 34s 15ms/step - loss: 1.6241 - acc: 0.5196\n",
            "Model: \"sequential_64\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_64 (Embedding)     (None, 40, 100)           6000      \n",
            "_________________________________________________________________\n",
            "gru_130 (GRU)                (None, 40, 32)            12864     \n",
            "_________________________________________________________________\n",
            "gru_131 (GRU)                (None, 128)               62208     \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 60)                7740      \n",
            "=================================================================\n",
            "Total params: 88,812\n",
            "Trainable params: 88,812\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c-IPWhs-Ucg",
        "outputId": "a669674f-16e5-427a-9856-eb37a50624ed"
      },
      "source": [
        "predicted_char = \"last year in france\"\r\n",
        "for i in range(100):\r\n",
        "    predicted_char = predicted_char + predict_char(character_2,predicted_char)\r\n",
        "print(predicted_char)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last year in francely citia . ghbern ivan cascaced of camicals in a peonzecparitia 's hospriciated instkreeptant groazw\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DFVhqvUbCxm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}